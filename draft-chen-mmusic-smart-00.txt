



mmusic                                                           W. Chen
Internet-Draft                                                       ABC
Intended status: Standards Track                                   J. Fu
Expires: April 13, 2019                              Cisco Systems, Inc.
                                                        October 10, 2018


           Simple Media Annotation for Real-Time comunication
                     draft-chen-mmusic-smart-00.txt

Abstract

   While AI technology arising, automatical video annotation, speech
   transcription and similar such technologies are becoming mature.
   This document proposes one solution to transfer and sync such meta
   data along the media in the context of RTCWeb.

Status of This Memo

   This Internet-Draft is submitted in full conformance with the
   provisions of BCP 78 and BCP 79.

   Internet-Drafts are working documents of the Internet Engineering
   Task Force (IETF).  Note that other groups may also distribute
   working documents as Internet-Drafts.  The list of current Internet-
   Drafts is at https://datatracker.ietf.org/drafts/current/.

   Internet-Drafts are draft documents valid for a maximum of six months
   and may be updated, replaced, or obsoleted by other documents at any
   time.  It is inappropriate to use Internet-Drafts as reference
   material or to cite them other than as "work in progress."

   This Internet-Draft will expire on April 13, 2019.

Copyright Notice

   Copyright (c) 2018 IETF Trust and the persons identified as the
   document authors.  All rights reserved.

   This document is subject to BCP 78 and the IETF Trust's Legal
   Provisions Relating to IETF Documents
   (https://trustee.ietf.org/license-info) in effect on the date of
   publication of this document.  Please review these documents
   carefully, as they describe your rights and restrictions with respect
   to this document.  Code Components extracted from this document must
   include Simplified BSD License text as described in Section 4.e of
   the Trust Legal Provisions and are provided without warranty as
   described in the Simplified BSD License.



Chen & Fu                Expires April 13, 2019                 [Page 1]

Internet-Draft                    SMART                     October 2018


Table of Contents

   1.  Introduction  . . . . . . . . . . . . . . . . . . . . . . . .   2
   2.  Message Format  . . . . . . . . . . . . . . . . . . . . . . .   4
     2.1.  Sub-message common header . . . . . . . . . . . . . . . .   4
     2.2.  SMART_RECTS . . . . . . . . . . . . . . . . . . . . . . .   5
   3.  SDP Negotiation . . . . . . . . . . . . . . . . . . . . . . .   6
     3.1.  Media Type Registration . . . . . . . . . . . . . . . . .   6
     3.2.  Example . . . . . . . . . . . . . . . . . . . . . . . . .   7
     3.3.  Send Through Data Channel . . . . . . . . . . . . . . . .   7
   4.  Synchronize with Media  . . . . . . . . . . . . . . . . . . .   7
     4.1.  Render a Media Annotation Frame . . . . . . . . . . . . .   8
     4.2.  RTCWeb implicition  . . . . . . . . . . . . . . . . . . .   8
   5.  Compatible  . . . . . . . . . . . . . . . . . . . . . . . . .   8
   6.  Security Considerations . . . . . . . . . . . . . . . . . . .   8
   7.  IANA Considerations . . . . . . . . . . . . . . . . . . . . .   8
   8.  Acknowledgements  . . . . . . . . . . . . . . . . . . . . . .   9
   9.  Normative References  . . . . . . . . . . . . . . . . . . . .   9
   Authors' Addresses  . . . . . . . . . . . . . . . . . . . . . . .   9

1.  Introduction

   Nowdays, face tracking and face recognition have already made a great
   progress and are widely adopted.  Face tracking can be used to smart
   cropping of the video avoiding the face being cut, face recognition
   can be used to identify who are engaged in the communication by
   labelling the name in the video.  Speech recognition technology
   becomes mature too, it is not surprised that speech can be
   automatically transcribed to text and assist the real time
   communications.  AI technology can be applied to other use cases,
   like object tracking, emotion detecting, simultaneous translation and
   so on.

                           +-----------------+
               +---------> | Media Processor +------------+
               |           +-----------------+            |
               |                                          |
               |                                          |
               |                                          |
               |                                          |
           +----+----+                               +-----v----+
           | Sender  |                               | Receiver |
           +---------+                               +----------+

                       Figure 1: Media Flow Topology

   In a real-time communication scenario like in Figure 1, these
   intellegent processing can be done at sender, media processor or



Chen & Fu                Expires April 13, 2019                 [Page 2]

Internet-Draft                    SMART                     October 2018


   receiver.  The advantage of doing it at receiver or media processor
   was backward compatibility but there are also disadvantages:

   1.  the media quality might degrade due to packet loss or delay on
       the network.

   2.  either all receivers needs to repeat the computation or extra
       server resources are required to compute it.

   3.  some meta data could be captured only on source side, for
       example, iPhone 3D camera could help extract more information
       than pure image processing.

   This document will focus on methods to capture the media meta data at
   sender side and define how to transfer them along with media data to
   the receiver.

   Mixing the meta data with media at the sender is one way to convey
   them to receivers , but there are some drawbacks, take compositing
   annotation text onto the source picture as an example:

   1.  If the video was degraded due to network, the text will be
       unclear.

   2.  The receiver can not turn on/off the annotation on-demand.

   3.  The receiver can not customize the utilization of such meta data.

   This document proposes a new out-of-band payload to transfer them and
   synchornize them through timestamp at receiver, rather than extending
   the current media payloads:

   1.  It is easier to achieve backward compatiblity.

   2.  The transportation of the meta data could be different from the
       media.  For example, the face tracking information could be
       combined with the audio transcribed text and render together.

   The mechanism described in this document can also be used to transfer
   other media meta data.  For example, for dekstop sharing case, the
   mouse movement events can be transfered separately in this format,
   and we can achieve higher frame rate of mouse movement than the
   screen content.








Chen & Fu                Expires April 13, 2019                 [Page 3]

Internet-Draft                    SMART                     October 2018


2.  Message Format

                       +---------------+---------------+
                       |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|
                       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
                       | V |   RES | P |      Count    |
                       +---+-------+---+---------------+

                      Figure 2: Common Message Header

   The message will have 2 bytes header followed with an array of sub-
   messages.  All sub-messages share the same common header as in
   Figure 2.

   V: Version.  The version of this message, it should be set to 0.

   RES:  Reserved.  The reserved field, should be set to 0 now.

   P: Priority.  The priority of the message, lower priority packets can
      be dropped or delayed.

   Count:  Count.  The number of sub-messages embedded.  There at least
      one submessage embedded, so the count plus one is the actual
      number of sub-messages.

2.1.  Sub-message common header

       +---------------+---------------+---------------+---------------+
       |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|
       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
       |     Type      |     Len       |              SSRC             |
       +---------------+---------------+---------------+---------------+
       |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|
       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
       |            ...SSRC            |          Timestamp            |
       +---------------+---------------+---------------+---------------+
       |       ...Timestamp            |
       +---------------+---------------+

                   Figure 3: General Sub-message Format

   Each sub-message will have at least 10 bytes headers, the details
   are:

   Type:  one-byte pre-defined sub-message type, see table 1.

   Len:  the length of the sub-message, not including the common header,
      in bytes



Chen & Fu                Expires April 13, 2019                 [Page 4]

Internet-Draft                    SMART                     October 2018


   SSRC:  4 bytes, the SSRC of the corresponding video stream even when
      this payload is generated from an audio stream.  The annotation
      should be rendered to the corresponding video stream.

   Timestamp:  4 bytes, the same [RFC3550] RTP timestamp space as the
      corresponding video stream.

   This document defines 1 sub-message type and they can be extended in
   future.

                   +------------------+----------+
                   |    Sub-message   |   Value  |
                   +------------------+----------+
                   |  SMART_RECTS     |     0    |
                   +------------------+----------+

                    Figure 4: Pre-defined Message Types

2.2.  SMART_RECTS

       +---------------+---------------+---------------+---------------+
       |0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|0|1|2|3|4|5|6|7|
       +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+
       |S|I|P|T|  RES  |   Name Len    |               ID              |
       +---------------+---------------+---------------+---------------+
       |             Left              |             Top               |
       +---------------+---------------+---------------+---------------+
       |             Width             |            Height             |
       +---------------+---------------+---------------+---------------+
       |          Time offset          |            Name...            |
       +---------------+---------------+---------------+---------------+

                   Figure 5: SMART_RECTS Message Format

   This pattern can be repeated, the total number of rectangles could be
   determined from the length field of the sub-message common header.
   Each filed of this sub-message is defined as:

   S: controls the Width/Height fields.  If it is 0, there is no Width/
      Height.

   I: controls the ID field.  If it is 0, there is no ID filed.

   P: synchornization policy.  Zero means it will be rendered as soon as
      possible when the message was received and one means it will be
      synchronized with video stream, please refer to "Synchronize with
      Media" section for detail.




Chen & Fu                Expires April 13, 2019                 [Page 5]

Internet-Draft                    SMART                     October 2018


   T: controls the Time offset field.  If it is 0, there is no time
      offset field.

   RES:  Reserved field, must be set to zero.

   Name Len:  the length of the name field, it can between 0 - 255.

   ID:  the identifier of the rectangle, value is defined by the app.

   Left/Top:  2 bytes each, the left top point of the rectangle.

   Width/Height:  2 bytes each, the width and height of the rectangle.

   Time offset:  the timestamp offset to the common header timestamp.
      This is useful when there is multiple submessages in one message
      to save the bandwidth.  The unit is the same as video RTP
      timestamp.

   Name:  the null-terminated UTF-8 string of the name tagging that
      rectangle, up to 255 bytes.

3.  SDP Negotiation

   The message can be sent along with RTP stream as RTP payload, it can
   also be sent through Data Channel in SCTP.

   When it is sent through RTP stream, it can be multiplexed with either
   Audio or Video stream with its own sequence space and separate SSRC,
   the payload type can be negotiated with dynamic payloads.

   Resilience technologies like FEC and RTP retransmission can be used
   on the annotation stream to provide some kind of reliablity when
   packet loss.  Or in separate RTP session over realiabe channel like
   SCTP or TCP.

3.1.  Media Type Registration

   Media type registration is done according to [RFC6838] and [RFC4855].

   Type name:  application

   Subtype name:  annotation

   Required parameters:

      type:  supported sub-message type values, use vertical bar to
         concatenate, for example, type=0|1, means it will generate both




Chen & Fu                Expires April 13, 2019                 [Page 6]

Internet-Draft                    SMART                     October 2018


         SMART_RECTS and SMART_TEXTS.  The type indicates how many
         payloads it could be encoded in the source side.

      Optional parameters:

         minptime:  the minimum interval of such meta data, in
            milliseconds

         maxbitrate:  the maximum bitrate of such meta data, in kbps
            units

3.2.  Example

    m=audio 5004 UDP/TLS/RTP/SAVPF 111 104
    c=IN IP4 47.98.240.10
    a=rtcp:9 IN IP4 0.0.0.0
    a=mid:audio
    a=sendrecv
    a=rtcp-mux
    a=rtpmap:111 opus/48000/2
    a=fmtp:111 minptime=10;sprop-stereo=0;stereo=0;usedtx=0;useinbandfec=1
    a=rtpmap:104 annotation/1000
    a=fmtp:104 type=1;maxbitrate=2

              Figure 6: Example SDP Offer with SMART Support

   In this example, 104 was selected for the media annotation and it
   will send along with audio stream.

3.3.  Send Through Data Channel

   TODO?

4.  Synchronize with Media

   There are 2 synchornization policis defined, one is no
   synchornization and they will be rendered as fast as they are
   decoded.  For example, the audio transcription should be updated even
   the video was frozen due to network degration.

   Sometime the frame needs to be synchornized with video stream, for
   example, the face tracking rectangle, it would be meaningless if the
   video was not up to date.

   In either of the case, the SSRC of the payload is used to find the
   corresponding video where the annotation should be rendered.
   Sometime, if there is a media relay, the corresponding video SSRC
   chould be CSRC of the receiving stream.



Chen & Fu                Expires April 13, 2019                 [Page 7]

Internet-Draft                    SMART                     October 2018


   The timestamp in the media annotation is the same unit as video RTP
   timestamp, and it doesn't need to be aligned to a video RTP
   timestamp.  The rendering of media annotation MUST NOT impact the
   synchronization of audio and video rendering.  It can be an add-on to
   the current media rendering.

   The media annotation should be displayed in the following video
   frames until the next annotation frame come.  If there is no up-
   coming frame for a long while, the application should hide them.

4.1.  Render a Media Annotation Frame

   When a media annotation frame is decoded, it checks if the timestamp
   is newer than the last rendered video frame.

   If the last video frame is newer, then it should patch the annotation
   into the rendered video frame and redraw the render view.  Any video
   frame after that should be patched with the annotation until the
   clear timer or next annotation frame come.

   If the annotation frame is newer, it should be cached in a FIFO queue
   and once next video frame comes, it will check if the annotation
   frame should be poped and patched into the video frame.

4.2.  RTCWeb implicition

   To achieve the synchornized video annotation, RTCWeb needs to open
   interface for application operating the rendering of the annotation
   with the video.  Exposure of the video raw data to JS layer and let
   application renders it with Canvas or WebGL would be a good choice.

5.  Compatible

   When the legacy endpoints received such an OFFER, it can just ignore
   the payload.

6.  Security Considerations

   Such meta data could be privacy as the same level of the media,
   sender can decide to not distribute them.  The meta data should be
   encrypted in the transer and it should also support end to end
   encription.

7.  IANA Considerations

   "application/annotation" media type should be registered as defined
   in [RFC6838].




Chen & Fu                Expires April 13, 2019                 [Page 8]

Internet-Draft                    SMART                     October 2018


8.  Acknowledgements

9.  Normative References

   [RFC3550]  Schulzrinne, H., Casner, S., Frederick, R., and V.
              Jacobson, "RTP: A Transport Protocol for Real-Time
              Applications", STD 64, RFC 3550, DOI 10.17487/RFC3550,
              July 2003, <https://www.rfc-editor.org/info/rfc3550>.

   [RFC4855]  Casner, S., "Media Type Registration of RTP Payload
              Formats", RFC 4855, DOI 10.17487/RFC4855, February 2007,
              <https://www.rfc-editor.org/info/rfc4855>.

   [RFC6838]  Freed, N., Klensin, J., and T. Hansen, "Media Type
              Specifications and Registration Procedures", BCP 13,
              RFC 6838, DOI 10.17487/RFC6838, January 2013,
              <https://www.rfc-editor.org/info/rfc6838>.

Authors' Addresses

   Wei Chen
   ABC
   2 YouZhi Nong, Road MaoJiaQiao
   HangZhou  310012
   China

   Phone: +86-013858060444
   Email: oeichenwei@gmail.com


   Jiantao Fu
   Cisco Systems, Inc.
   771 Alder Dr
   Milpitas  95035
   USA

   Phone: +1-510-403-5644
   Email: jianfu@cisco.com













Chen & Fu                Expires April 13, 2019                 [Page 9]
